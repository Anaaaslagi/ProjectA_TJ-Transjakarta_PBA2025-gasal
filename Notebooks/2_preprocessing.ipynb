{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1f5459",
   "metadata": {},
   "source": [
    "# Tahap 2: Preprocessing Teks Berita Transjakarta\n",
    "\n",
    "## Pastikan Anda sudah menginstal library yang dibutuhkan:\n",
    "## pip install pandas sastrawi nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c739e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffefb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup Awal (Download kamus NLTK jika belum ada) ---\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5699e652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../Data/hasil_scraping_transjakarta.csv' berhasil dibaca. Jumlah data awal: 150 baris.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Membaca File Hasil Scraping ---\n",
    "input_filepath = '../Data/hasil_scraping_transjakarta.csv'\n",
    "try:\n",
    "    df = pd.read_csv(input_filepath, sep=';')\n",
    "    print(f\"File '{input_filepath}' berhasil dibaca. Jumlah data awal: {len(df)} baris.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{input_filepath}' tidak ditemukan. Pastikan file ini ada di folder yang sama.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "547e9724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data setelah membuang konten kosong: 150 baris.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Pembersihan Awal ---\n",
    "# Buang baris yang tidak punya isi berita\n",
    "df.dropna(subset=['Isi Berita'], inplace=True)\n",
    "df = df[~df['Isi Berita'].str.contains(\"Konten tidak ditemukan\", na=False)]\n",
    "print(f\"Jumlah data setelah membuang konten kosong: {len(df)} baris.\")\n",
    "\n",
    "# Gabungkan Judul dan Isi Berita menjadi satu kolom\n",
    "df['Teks_Lengkap'] = df['Judul'].astype(str) + \" \" + df['Isi Berita'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473fd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Fungsi-fungsi untuk Preprocessing ---\n",
    "\n",
    "# a. Case Folding\n",
    "def case_folding(text):\n",
    "    return text.lower()\n",
    "\n",
    "# b. Pembersihan Noise\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text) # Hapus URL\n",
    "    text = re.sub(r'<.*?>', '', text) # Hapus tag HTML\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Hapus angka dan tanda baca\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Hapus spasi berlebih\n",
    "    return text\n",
    "\n",
    "# c. Normalisasi Kata (contoh kamus, bisa ditambahkan)\n",
    "def normalize_words(text):\n",
    "    slang_dict = {\n",
    "        'yg': 'yang', 'ga': 'tidak', 'gak': 'tidak', 'utk': 'untuk', 'dgn': 'dengan',\n",
    "        'kalo': 'kalau', 'aja': 'saja', 'udah': 'sudah', 'transj': 'transjakarta',\n",
    "        'mrt': 'moda raya terpadu', 'lrt': 'lintas rel terpadu'\n",
    "        # Tambahkan kata lainnya jika ditemukan\n",
    "    }\n",
    "    words = text.split()\n",
    "    normalized_words = [slang_dict.get(word, word) for word in words]\n",
    "    return ' '.join(normalized_words)\n",
    "\n",
    "# d. Stopword Removal\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopword_list = stopword_factory.get_stop_words()\n",
    "# Tambahkan stopword custom jika perlu\n",
    "stopword_list.extend(['rp', 'dki', 'jakarta']) \n",
    "stopword_remover = stopword_factory.create_stop_word_remover()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return stopword_remover.remove(text)\n",
    "\n",
    "# e. Stemming\n",
    "stemmer_factory = StemmerFactory()\n",
    "stemmer = stemmer_factory.create_stemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    return stemmer.stem(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71124366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai proses preprocessing...\n",
      "Stopword removal selesai.\n",
      "Stemming selesai.\n",
      "Preprocessing selesai. Jumlah data akhir: 150\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Menjalankan Pipeline Preprocessing ---\n",
    "print(\"\\nMemulai proses preprocessing...\")\n",
    "\n",
    "# Terapkan semua fungsi ke kolom 'Teks_Lengkap'\n",
    "# Proses ini mungkin memakan waktu beberapa menit, terutama stemming\n",
    "df['Teks_Bersih'] = df['Teks_Lengkap'].apply(case_folding)\n",
    "df['Teks_Bersih'] = df['Teks_Bersih'].apply(clean_text)\n",
    "df['Teks_Bersih'] = df['Teks_Bersih'].apply(normalize_words)\n",
    "df['Teks_Bersih'] = df['Teks_Bersih'].apply(remove_stopwords)\n",
    "print(\"Stopword removal selesai.\")\n",
    "df['Teks_Stemmed'] = df['Teks_Bersih'].apply(stem_text)\n",
    "print(\"Stemming selesai.\")\n",
    "\n",
    "print(\"Preprocessing selesai. Jumlah data akhir:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e933ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Proses preprocessing selesai. Hasil disimpan di file: ../Data/hasil_preprocessing_transjakarta.csv\n",
      "\n",
      "Cuplikan 5 baris pertama dari data hasil preprocessing:\n",
      "                                        Teks_Lengkap  \\\n",
      "0  Hore! Naik Transjakarta, MRT, LRT Jakarta Rp 1...   \n",
      "1  Sejumlah Layanan Transjakarta Terganggu Imbas ...   \n",
      "2  Truk Mogok di Jalan Gatsu Arah Cawang, Sejumla...   \n",
      "3  Rano Karno: Rute TransJakarta Ancol-Blok M Aka...   \n",
      "4  Bus Listrik Transjakarta Kecelakaan di Setiabu...   \n",
      "\n",
      "                                        Teks_Stemmed  \n",
      "0  hore transjakarta moda raya padu lintas rel pa...  \n",
      "1  layan transjakarta ganggu imbas demo daftar ru...  \n",
      "2  truk mogok jalan gatsu arah cawang rute transj...  \n",
      "3  rano karno rute transjakarta ancolblok luncur ...  \n",
      "4  bus listrik transjakarta celaka setiabudi rem ...  \n"
     ]
    }
   ],
   "source": [
    "# --- 5. Menyimpan Hasil ---\n",
    "output_filepath = '../Data/hasil_preprocessing_transjakarta.csv'\n",
    "# Pilih kolom yang relevan untuk disimpan\n",
    "kolom_untuk_disimpan = [\n",
    "    'No', 'Link', 'Sumber', 'Tanggal', 'Tag', 'PIC',\n",
    "    'Teks_Lengkap', 'Teks_Bersih', 'Teks_Stemmed'\n",
    "]\n",
    "df_final = df[kolom_untuk_disimpan]\n",
    "df_final.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\n✅ Proses preprocessing selesai. Hasil disimpan di file: {output_filepath}\")\n",
    "\n",
    "# Menampilkan 5 baris pertama dari hasil akhir\n",
    "print(\"\\nCuplikan 5 baris pertama dari data hasil preprocessing:\")\n",
    "print(df_final[['Teks_Lengkap', 'Teks_Stemmed']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
